# spark submit options
submit --class  com.alstom.datalab.Main
#submit --num-executors   17
#submit --executor-cores  3
submit --executor-memory  10G
#submit --driver-memory  8G
submit --conf spark.sql.shuffle.partitions=20
submit --conf spark.sql.autoBroadcastJoinThreshold=52428800
submit --conf spark.KryoSerializer.buffer.max=128m
#submit --conf spark.hadoop.mapred.output.committer.class=com.alstom.datalab.hadoop.DirectOutputCommitter
#submit --conf spark.storage.memoryFraction=0.2
#submit --conf spark.shuffle.memoryFraction=0.4
# command arguments
args --method WebApp
args --repo hdfs:///data/repo
args --dirin hdfs:///data/out/aggregated
args --dirout s3n://gewebapp
args --control hdfs:///data/control
args --meta hdfs:///data/meta
args --partition 16
# shell specific options
shell.dirin hdfs:///data/control
shell.dirdone hdfs:///data/done
shell.batchfilesize 100