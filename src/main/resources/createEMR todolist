#When creating new EMR cluster :
EMRMASTER="ec2-54-209-81-97.compute-1.amazonaws.com"
ALDATALABDIR="/Users/guillaumepinot/Dev/Alstom/V2/script/spark/IdeaProjects/ALDataLab"

ssh -i ~/Dev/AWS/Credentials/KeyLezoomerUs.pem hadoop@$EMRMASTER "if [[ ! -d script ]]; then mkdir script;fi;if [[ ! -d lib ]]; then mkdir lib;fi"
scp -i ~/Dev/AWS/Credentials/KeyLezoomerUs.pem $ALDATALABDIR/target/scala-2.10/ALDataLab-assembly-1.1.jar hadoop@$EMRMASTER:~/lib
scp -i ~/Dev/AWS/Credentials/KeyLezoomerUs.pem ALDATALABDIR/client/script/ALDataLab-client.sh hadoop@$EMRMASTER:~/script
scp -i ~/Dev/AWS/Credentials/KeyLezoomerUs.pem ALDATALABDIR/client/script/distributeByBatch.sh hadoop@$EMRMASTER:~/script
ssh -i ~/Dev/AWS/Credentials/KeyLezoomerUs.pem hadoop@$EMRMASTER "chmod +x script/*.sh"

#Patch /etc/zeppelin/conf/zeppelin-env.sh :
export CLASSPATH="/usr/share/aws/aws-java-sdk/*:/usr/lib/hadoop-lzo/lib/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*"
#Add S3 notebook
export ZEPPELIN_NOTEBOOK_S3_BUCKET="gezeppelin"
export ZEPPELIN_NOTEBOOK_S3_USER="zeppelin"

#zeppelin-site.xml :
<property>
  <name>zeppelin.notebook.s3.user</name>
  <value>zeppelin</value>
  <description>user name for s3 folder structure</description>
</property>

<property>
  <name>zeppelin.notebook.s3.bucket</name>
  <value>gezeppelin</value>
  <description>bucket name for notebook storage</description>
</property>

<property>
  <name>zeppelin.notebook.storage</name>
  <value>org.apache.zeppelin.notebook.repo.S3NotebookRepo</value>
  <description>notebook persistence layer implementation</description>
</property>

<!--
<property>
  <name>zeppelin.notebook.storage</name>
  <value>org.apache.zeppelin.notebook.repo.VFSNotebookRepo</value>
  <description>notebook persistence layer implementation</description>
</property>
-->

#Add following line in /etc/spark/conf/spark-defaults.conf
spark.dynamicAllocation.enabled true

Add rluta public key in .ssh/Authorized




#ec2 spark cluster
cd /Users/guillaumepinot/Dev/spark-1.5.2-bin-2.7.1/ec2
./spark-ec2 --key-pair=KeyLezoomerUs --identity-file=/Users/guillaumepinot/Dev/AWS/Credentials/KeyLezoomerUs.pem --region=us-east-1 --zone=us-east-1a --spot-price=0.045 --instance-type=m3.xlarge --copy-aws-credentials -s 3 --user datalab --master-instance-type=m3.xlarge launch gespark