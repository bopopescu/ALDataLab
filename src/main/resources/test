/////////////////////////////////////////////////////////////////////////////
//pour spark-shell
/////////////////////////////////////////////////////////////////////////////

spark-shell --master yarn --driver-memory 2G --executor-memory 8G --jars ./lib/ALDataLab-assembly-1.0.jar


sqlContext.setConf("spark.sql.shuffle.partitions", "10")
import dlenv._
import dlutil._
import dlpipeline._
import DLRepo._

val D_Root="s3://alstomlezoomerus"

val pipe=new dlpipeline(D_Root+"/DATA/Repository")
val repo = new dlrepo(D_Root+"/DATA/Repository")


repo.ProcessInFile(sqlContext, D_Root + "/DATA/Repository/in/MDM-ITC_20151117.csv")
repo.ProcessInFile(sqlContext, D_Root + "/DATA/Repository/in/I-ID_20151101.csv")
repo.ProcessInFile(sqlContext, D_Root + "/DATA/Repository/in/AIP-Application_20151117.csv")
repo.ProcessInFile(sqlContext, D_Root + "/DATA/Repository/in/AIP-Server_20151117.csv")
repo.ProcessInFile(sqlContext, D_Root + "/DATA/Repository/in/AIP-SoftInstance_20151117.csv")
repo.genAIP(sqlContext)

val dfMDM=repo.readMDM(sqlContext)

val dfAIPServer = repo.readAIPServer(sqlContext)
val dfAIPSoftInstance = repo.readAIPSoftInstance(sqlContext)
val dfAIPApplication = repo.readAIPApplication(sqlContext)

val dfAIP = repo.readAIP(sqlContext)
val ipdup = dfAIP.groupBy("aip_server_ip").agg(count("aip_server_ip") as "count_ip").filter($"count_ip" > 1).select("aip_server_ip").withColumnRenamed("aip_server_ip", "ip")

val df = dfAIP.join(ipdup, dfAIP("aip_server_ip") <=> ipdup("ip"), "inner")

df.sort(asc("aip_server_ip"))


pipe.pipeline2to3(sc, sqlContext, D_Root + "/DATA/2-NXFile/connection_sabad11478.ad.sys_20151031.tgz.csv.gz", D_Root + "/DATA/3-NXFile")
pipe.pipeline2to3(sc, sqlContext, D_Root + "/DATA/2-NXFile/webrequest_sabad11478.ad.sys_20151031.tgz.csv.gz", D_Root + "/DATA/3-NXFile")
pipe.pipeline2to3(sc, sqlContext, D_Root + "/DATA/2-NXFile/connection_sabad11479.ad.sys_20151031.tgz.csv.gz", D_Root + "/DATA/3-NXFile")
pipe.pipeline2to3(sc, sqlContext, D_Root + "/DATA/2-NXFile/webrequest_sabad11479.ad.sys_20151031.tgz.csv.gz", D_Root + "/DATA/3-NXFile")
pipe.pipeline3to4(sc, sqlContext, D_Root + "/DATA/3-NXFile/connection_sabad15034.ad.sys_2015-10-01.parquet", D_Root + "/DATATEST/5-NXFile", D_Root + "/DATATEST/4-NXFile")



/////////////////////////////////////////////////////////////////////////////
Commandes spark-submit
/////////////////////////////////////////////////////////////////////////////

spark-submit --master yarn --driver-memory 2G --executor-memory 8G --class DLMain.DLMain file:///home/hadoop/lib/ALDataLab-assembly-1.0.jar --D_REPO s3://alstomlezoomerus/DATA/Repository --method pipeline3to4 s3://alstomlezoomerus/DATA/3-NXFile/connection_sabad11478.ad.sys_2015-10-30.parquet s3://alstomlezoomerus/DATA/5-NXFile s3://alstomlezoomerus/DATA/4-NXFile



/////////////////////////////////////////////////////////////////////////////
Commandes shell (appel√©es en cron)
/////////////////////////////////////////////////////////////////////////////
/home/hadoop/script/ALDataLab-client.sh "s3://alstomlezoomerus/DATA/Repository" "s3://alstomlezoomerus/DATA/Repository/in/" "csv" "s3" ".todo" "RepoProcessInFile"
/home/hadoop/script/ALDataLab-client.sh "s3://alstomlezoomerus/DATA/Repository" "s3://alstomlezoomerus/DATA/2-NXFile" "sabad11478" "s3" ".todo" "pipeline2to3" "s3://alstomlezoomerus/DATA/3-NXFile"
/home/hadoop/script/ALDataLab-client.sh "s3://alstomlezoomerus/DATA/Repository" "s3://alstomlezoomerus/DATA/3-NXFile" "sabad11478" "s3" ".todo" "pipeline3to4" "s3://alstomlezoomerus/DATA/4-NXFile"





#divers shell
function lstpipegap {
    filedone=$(aws s3 ls s3://alstomlezoomerus/DATA/3-NXFile/ | grep -v folder | grep -v todo| awk '{if ($1 == "PRE") {print $2} else {print $4}}' | sed "s/\/$//" )
    filetodo=$(aws s3 ls s3://alstomlezoomerus/DATA/3-NXFile/ | grep -v folder | grep todo| awk '{if ($1 == "PRE") {print $2} else {print $4}}' | sed "s/\.todo\/$//" | sed "s/\.todo$//")

    ResFileDone=""
    ResFileNotTodo=""
    for filein in $filedone
    do
        if echo $filetodo | grep -q $filein; then
            ResFileTodo="$ResFileNotTodo $filein"
        else
            echo "$filein done"
            ResFileDone="$ResFileDone $filein"
        fi
    done

}
