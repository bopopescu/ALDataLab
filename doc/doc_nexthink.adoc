<<<
== Nexthink

=== What is Nexthink ?

Nexthink is the application which collects information about any actions done on a PC, Laptop or a server.
See image below.
footnote:[https://doc.nexthink.com/images/a/a3/Collector.png]

image::images/collector.png[title="Nexthink Engine which collects data from different devices", width="320", height="200"]


A Nexthink _Collector_ program installed on different devices captures network connections, program executions, web requests, etc.. and sends data to Nexthink _Engines_.
Nexthink _Engines_ stock received data and make daily backups.

=== Where are data collection on Nexthink side ?

image::images/nexthink_collector_engins.jpg[title="Nexthink Engines with backup servers", float="right", width="300", height="350"]

There are two groups of Nexthink servers on which collected data are stored.

* _Data collected from PCs, laptops, etc._ There are 21 servers and the version of Nexthink installed is V5.

* _Data collected from Servers_. There are 3 servers in this group. The version of Nexthink is V6.

As a result, data storing and backup processes are different on both kind of engines/servers.

WARNING: Furthermore, archived data aren't kept for a life on backup servers.
As soon as more data are coming, the very old once are erased.


=== How we get and store input data on our side ?

_Collector_ server (SARMA10012) copies these data from Nexthink backup servers to our SAN server every 3 days.
Each received file can contain log history of 5 to 20 days.

NOTE: As we try to collect these data every 3 days in order to not loose any part of them, this causes us some overlaps.
This is why we should make attention to filter duplicated data during analysis processes.

==== How input data are used ?

Provided data stored under SAN server in */0/ folder* are considered as _input data_.
As they are collected by Nexthink way, they are not in any columnar format (CSV, parquet, etc.).
This is why the very first step is to extract these data into CSV format with the help of a Nexthink environment.
We have 2 virtual machines (named as VM5 and VM6) on the Collector server which are dedicated to this purpose.
VM6 is used to extract data collected from servers and VM5 for the rest.

image::images/extract_anonymize.jpg[title="Data extraction and anonymization", align="center", width="450", height="250"]

==== Extract-backup

Input data are deployed either on VM5 or VM6 to be extracted.
We use NXQL sql requests to extract information and we store them in CSV formats.
This operation is executed daily and we call it as _extractbackup_.

Extracted data are copied on */1/ folder*.
At this stage, they are ready to be anonymized.



//Finally, extracted data is anonymized via VM20 and stored on s3://collect/nexthink/in.





After extracting, we separate 3 data types under /1/ folder.

* _connection_ - anything related to users' "connection" (TCP, UDP, etc..)

Information collected about any outgoing (and only outgoing) network requests,
such as which user is connected, by which application,
IP address requested, HTTP protocol used, server port number,
request execution time, request content size, etc.
These information are mainly related to the source device of the requests.
It can be a simple user machine but also a server.

* _webrequest_ - anything related to a "webrequest" (DNS information)

This kind of data are captured while a web request (HTTP) is detected.
Some information about the target device is collected, such as request's DNS address (google, etc.), etc.
However, full URL of web requests are not registered at all.


* _execution_ - anything related to an application "execution"

These are information about the execution of any application used by users.
This concern also applications which do not access to internet.
(even if a user doesn't login to the application).

These kind of data give us information about which application is executed,
by which user, at what time, the version of the application,
how much does it take to be started, the path to the application, etc.


As a result, there are 3 main folders ( _/connection_, /_webrequest_, /_execution_) under s3 server
for each of these types of data collections.


//[TIP]give a picture from cyberdock with highlighted colors of these folders.

=== Anonymization

The next step in the process is to make anonymous some user information from extracted data.
As usual, we use virtual machine VM20 for this purpose.
Once done, we store them under /2/ folder on the SAN server in CSV format.


Finally, these data are copied to _s3://gedatalab/in._

Source code path: ALDatalab/collect/nexthink.