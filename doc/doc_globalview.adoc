<<<
== Global View

Before presenting one by one of these collections and their usage analysis, here is an image
which shows common processes which are applied during various steps.

image::images/collect_pipeline.jpg[title="Global view of the common processes", width="650", height="350"]


Generally, the input data arrive to SAN server.
They are extracted into correct formats and made anonymous if necessary and stored on s3.
When needed they are copied to HDFS and analysed on the pipeline processes.
And IDM are used to resolve data if they are made anonymous.
In the following chapters we'll give some more detailed information about all of these items and processes.


Collector server (which is named as SARMA10012) collects different kind of data sources
which are _nexthink_, _server-usage_, _server-socket_, _oracle-log_.
While the way we collect them varies, common actions are performed
and same environments are used to process and analyse them.

The main object is to collect all information and put them on the local SAN server.
Later, we use VM20 to anonymize these information.
And anonymous data are saved under SAN server.
Finally it is sent to s3 server.


Collector server have access to IDM data which must be anonymized before sending to s3.


It creates the anonymized IDM which is named as I-ID.
This is because we could later be able to know what is the sector, team, site of an anonymized user.


A dictionary file (dictionary.csv) is created under SAN server to keep information about which user data correspond to which I-ID.
The collector server is the one which can tell us which anonymized user matches with its real information.


Nexthink, server usage and server socket are then used inside of the process named "Pipeline".
