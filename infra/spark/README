###This folder contains a script, spark-ec2, for launching Spark clusters on
Amazon EC2. Usage instructions are available online at: http://spark.apache.org/docs/latest/ec2-scripts.html

####To create a cluster, execute following commands
  - zeppelin.gadatalab.com :
    - ./spark-ec2 -k KeyLezoomerUs -i ~/.ssh/KeyLezoomerUs.pem --pipeline-version=1.3.3 --scala-version 2.11 --region=us-east-1 --zone=us-east-1b --instance-type m1.xlarge --master-instance-type m1.xlarge --spot-price 0.13 --master-spot-price 0.13 --deploy-env prod --zeppelin-bucket gecustomers --es-security-group elasticsearch-discovery --deploy-profile customers --instance-profile-name customers -s 5 launch zeppelin-prod
    - on web proxy server, associate new master IP to zeppelin upstream in /etc/nginx/conf.d/upstreams.conf file and restart nginx
  - devzeppelin.gadatalab.com :
    - ./spark-ec2 -k KeyLezoomerUs -i ~/.ssh/KeyLezoomerUs.pem --pipeline-version=1.3.3 --scala-version 2.11 --region=us-east-1 --zone=us-east-1b --instance-type m1.xlarge --master-instance-type m1.xlarge --spot-price 0.13 --master-spot-price 0.13 --deploy-env dev --zeppelin-bucket gecustomers --es-security-group elasticsearch-discovery --deploy-profile customers --instance-profile-name customers -s 10 launch zeppelin-dev
    - on web proxy server, associate new master IP to dev.zeppelin upstream in /etc/nginx/conf.d/upstreams.conf file and restart nginx
  - pipeline (no public url, use private ssh tunnel to access zeppelin (localhost:8080) :
    - ./spark-ec2 -k KeyLezoomerUs -i ~/.ssh/KeyLezoomerUs.pem --pipeline-version=1.3.3 --scala-version 2.11 --region=us-east-1 --zone=us-east-1b --instance-type m1.xlarge --master-instance-type m1.xlarge --spot-price 0.13 --master-spot-price 0.13 --deploy-env pipeline --zeppelin-bucket gezeppelin --es-security-group elasticsearch-discovery --copy-aws-credentials -s 25 launch pipeline
